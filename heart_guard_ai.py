# -*- coding: utf-8 -*-
"""Heart-Guard-AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1REet0h7HREfNd8FF7OtCJHnq97PeWxjP
"""

#Mount google drive
from google.colab import drive
drive.mount('/content/drive')

#import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn import tree #visualization of the decision tree

#change max columns
pd.set_option('display.max_columns',100)

#load dataset
df = pd.read_csv('/content/drive/MyDrive/CAD.csv')

df.shape

df.columns

#checking for cardinality of columns
df.nunique()

df['Cath'].unique()#classification problem

#determning how balanced the classes are
df['Cath'].value_counts()

df.columns
df.info()
df.head()

df.columns

#drop some columns with high correlation
df.drop('Weight', axis=1, inplace=True)
df.drop('Length', axis=1, inplace=True)

df.columns

#defining features matrix and target vector
X = df.drop('Cath', axis=1) #X is the variable holding the features
y = df['Cath'] #y is the target

#train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

#establishing the length of the training and test sets
print(len(X_train))
print(len(y_train))
print(len(X_test))
print(len(y_test))

X_train.head(3)

y_train.head(3)

#one hot encoding,numerical scaling and ordinal encoding
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

#list of numercial cols
num_cols= X_train.select_dtypes(include=['int64', 'float64']).columns
num_cols

#list of categorical cols
cat_cols= X_train.select_dtypes(include=['object','bool']).columns
cat_cols

#list of ordinal cols
ord_cols=['Region RWMA','Function Class']
ord_cols

#list of nominal cols
nominal_cols=['Sex', 'Obesity', 'CRF', 'CVA', 'Airway disease', 'Thyroid Disease','CHF', 'DLP', 'Weak Peripheral Pulse', 'Lung rales', 'Systolic Murmur', 'Diastolic Murmur', 'Dyspnea', 'Atypical', 'Nonanginal','Exertional CP', 'LowTH Ang', 'LVH', 'Poor R Progression', 'VHD']
nominal_cols

print(df['Region RWMA'].unique())
print(df['Function Class'].unique())

#defining the order for each ordinal column
Region_RWMA_order=[0, 1, 2, 3, 4]
Function_Class_order=[0, 1, 2, 3]

#list of order lists
cat_ord_list=[Region_RWMA_order,Function_Class_order]
cat_ord_list

from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler
from sklearn.pipeline import make_pipeline

#creating a numeric transformer
numerical_transformer= make_pipeline(StandardScaler())

#creating a nominal transformer
nominal_transformer= make_pipeline(OneHotEncoder(sparse_output=False, handle_unknown='ignore'))

#creating an ordinal transformer
ordinal_transformer= make_pipeline(OrdinalEncoder(categories=cat_ord_list))

#creating a pipeline
preprocessor= make_column_transformer(
    (numerical_transformer, num_cols),
    (nominal_transformer, nominal_cols),
    (ordinal_transformer, ord_cols)
)

#applying pipline to data
X_train_processed= preprocessor.fit_transform(X_train)
X_test_processed= preprocessor.transform(X_test)

#randomforestclassifer
from sklearn.ensemble import RandomForestClassifier

#instantitate random forest
model_RF= RandomForestClassifier(n_estimators=100, random_state=42)

#train model
model_RF.fit(X_train_processed,y_train)

#get features importnace from trained model
feautures_importance= model_RF.feature_importances_

#sorting important features by descending order

# Get the feature names after preprocessing
processed_feature_names = preprocessor.get_feature_names_out()

importances_df= pd.DataFrame({'feature': processed_feature_names, 'importance': feautures_importance})
importances_df= importances_df.sort_values('importance', ascending=False)

# Print the top 20 most important features
print("Top 20 most important features:")
print(importances_df.head(20))

#design model
from sklearn.tree import DecisionTreeClassifier

# instantiate a decision tree
dec_tree= DecisionTreeClassifier(random_state=42)

dec_tree.fit(X_train_processed,y_train)

#Testing the model to obtain predictions.
dec_pred= dec_tree.predict(X_test_processed)

#predicted values
dec_pred

y_train.value_counts()

#class_names
target_names=['No CAD','CAD']

#features names
feature_names= preprocessor.get_feature_names_out()

#decision tree visualisation
plt.figure(figsize=(30,20))
tree.plot_tree(dec_tree,filled=True, feature_names=preprocessor.get_feature_names_out(),class_names=target_names)

#first split with a feature with high information gain
y_train.value_counts()

#evaluation metrics library
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay

precision_score(y_test, dec_pred, average='weighted')

precision_score(y_test, dec_pred, average='macro')

#evaluating model
classification_report(y_test, dec_pred)

accuracy_score(y_test, dec_pred)

confusion_matrix(y_test, dec_pred)

ConfusionMatrixDisplay.from_predictions(y_test,dec_pred, cmap='Blues')

"""KNN CLASSIFIER"""

#importing the KNN classifier
from sklearn.neighbors import KNeighborsClassifier

#instantiate object
knn= KNeighborsClassifier(n_neighbors=21)

#train the model
knn.fit(X_train_processed,y_train)

#test the model
knn_pred= knn.predict(X_test_processed)

print(classification_report(y_test, knn_pred))

accuracy_score(y_test, knn_pred)

confusion_matrix(y_test, knn_pred)

ConfusionMatrixDisplay.from_predictions(y_test,dec_pred, cmap='Reds')

"""DEPLOYING MODEL"""

#importing necessary libraries
import pickle

# saving the model
filename= 'knn_model.sav'
pickle.dump(knn, open(filename, 'wb')) #wb-writing in binary

#downlaoding model
from google.colab import files
files.download('knn_model.sav')

loaded_knn_model = pickle.load(open(filename, 'rb')) #rb-reading in binary

# Save the preprocessor
preprocessor_filename = 'preprocessor.sav'
pickle.dump(preprocessor, open(preprocessor_filename, 'wb'))

#downloading preprocessor
from google.colab import files
files.download('preprocessor.sav')